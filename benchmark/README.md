# Benchmark System â€“ OpenCore Framework

A comprehensive benchmark suite designed to measure the performance, scalability, and internal overhead of the OpenCore framework under realistic and stress conditions.

This repository focuses on **measurable data**, not marketing numbers.

---

## ğŸ“‹ Description

The benchmark system evaluates OpenCore in two complementary dimensions:

1. **Core Benchmarks (Tinybench)**  
   Pure framework internals, without FiveM dependencies.

2. **Load Benchmarks (Vitest)**  
   Simulated FiveM-like workloads with multiple virtual players, commands, and net events.

---

## ğŸ—ï¸ Architecture

### Core Benchmarks (Tinybench)

Benchmarks targeting internal building blocks:

- **MetadataScanner** â€“ decorator scanning & reflection
- **Dependency Injection** â€“ tsyringe resolution cost
- **Zod Validation** â€“ simple, complex and nested schemas
- **RateLimiterService** â€“ key-based throttling under load
- **AccessControlService** â€“ rank & permission checks
- **CoreEventBus** â€“ event dispatch with variable handlers
- **Decorators** â€“ metadata definition & read overhead
- **ParallelCompute** â€“ sync vs parallel compute utilities

### Load Benchmarks (Vitest)

FiveM-like load simulation with increasing concurrency:

- **Commands** â€“ simple, validated, concurrent, end-to-end
- **Net Events** â€“ serialization, validation, latency injection
- **Guards & Throttle** â€“ permission and rate enforcement
- **Event Bus** â€“ handler fan-out under concurrency
- **Bootstrap** â€“ controller & metadata initialization
- **Pipeline** â€“ full execution chain
- **Player Lifecycle** â€“ bind / unbind / link operations
- **Stress Tests** â€“ mixed scenarios with ticks, commands and events

---

## ğŸš€ Usage

### Installation

```bash
pnpm install
```

### Run Benchmarks

#### Core Benchmarks

```bash
pnpm bench:core
# or
pnpm bench --core
```

#### Load Benchmarks

```bash
pnpm bench:load
```

#### Full Suite

```bash
pnpm bench:all
```

---

## ğŸ“Š Reports

All runs generate reports in `benchmark/reports/`:

- **`.txt`** â€“ human-readable summary
- **`.json`** â€“ machine-readable (CI, regression tracking)
- **`.html`** â€“ interactive visual report

Load benchmarks also maintain a rolling metrics file:

```
benchmark/reports/.load-metrics.json
```

These files are considered **local artifacts** and are typically gitignored.

---

## ğŸ“ˆ Latest Benchmark Results

**Framework version:** `0.2.2-beta.1`  
**Run date:** Dec 22, 2025  
**Environment:** Local development machine (results vary by hardware)

> âš ï¸ The following is a **snapshot**, not a guarantee.  
> Always consult the generated reports for authoritative data.

---

### ğŸ”¹ Core Benchmarks (Tinybench)

| Component                                  | Throughput    | Mean Time |
| ------------------------------------------ | ------------- | --------- |
| Decorators â€“ define metadata (Command)     | ~5.7M ops/sec | ~0.17 Î¼s  |
| EventBus â€“ multiple event types            | ~2.0M ops/sec | ~0.50 Î¼s  |
| DI â€“ resolve simple service                | ~1.7M ops/sec | ~0.58 Î¼s  |
| Zod â€“ simple schema validation             | ~2.5M ops/sec | ~0.40 Î¼s  |
| ParallelCompute â€“ overhead (sync, minimal) | ~4.7M ops/sec | ~0.21 Î¼s  |

---

### ğŸ”¹ Load Benchmarks (Vitest)

#### Net Events

| Scenario                      | Players | Throughput     | p95 latency |
| ----------------------------- | ------- | -------------- | ----------- |
| Simple net event              | 50      | ~3.7M ops/sec  | ~0.002 ms   |
| Concurrent net events         | 500     | ~1.17M ops/sec | ~0.40 ms    |
| With simulated latency (5 ms) | 50      | ~2.5K ops/sec  | ~16 ms      |

#### Commands (Full Pipeline)

| Scenario             | Players | Throughput     | p95 latency |
| -------------------- | ------- | -------------- | ----------- |
| Validated command    | 100     | ~3.1M ops/sec  | ~0.004 ms   |
| Validated command    | 500     | ~14.0M ops/sec | ~0.004 ms   |
| Concurrent execution | 500     | ~25K ops/sec   | ~19 ms      |
| End-to-end pipeline  | 500     | ~47K ops/sec   | ~0.13 ms    |

---

## ğŸ“ Directory Structure

```
benchmark/
â”œâ”€â”€ core/          # Tinybench benchmarks
â”œâ”€â”€ load/          # Vitest load benchmarks
â”œâ”€â”€ utils/         # Shared benchmark utilities
â”œâ”€â”€ reports/       # Generated reports (gitignored)
â”œâ”€â”€ index.ts       # Entry point
â””â”€â”€ README.md
```

---

## ğŸ¯ Goals

This benchmark system exists to:

1. **Quantify performance** â€“ not assume it
2. **Validate scalability** â€“ 10 â†’ 500 players
3. **Detect regressions** â€“ across versions
4. **Expose bottlenecks** â€“ early and visibly
5. **Support documentation** â€“ with real numbers

---

## ğŸ“ Notes

- Benchmarks are CPU-bound and hardware-dependent
- Latency-injected scenarios simulate network conditions
- Results should be compared **relatively**, not absolutely
- This system is intended for regression tracking, not marketing claims

---

## ğŸ“„ License

MPL-2.0 â€“ see LICENSE in the project root
